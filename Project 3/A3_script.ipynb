{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EECS 4422 Assignment 3\n",
    "\n",
    "Jimmy Le<br>\n",
    "216143992<br>\n",
    "Prof. Kosta Derpanis<br>\n",
    "EECS4422 W2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks:\n",
    "\n",
    "o Implement RANSAC based image stitching<br>\n",
    "o Implement Panorama Construction<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import kornia\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" #Prevents an unusual error where displaying images will crash the kernel?\n",
    "#rcParams['figure.figsize'] = 11,8\n",
    "plt.gray() #Ensures greyscale images are displayed gray without having to use cmap parameter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays Tensors as image\n",
    "def imshowTorch(input):\n",
    "    image = kornia.tensor_to_image(input) #Converts to HWC format\n",
    "    plt.imshow(image) #As matplotlib requires arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts numpy arrays to Kornia compatable tensors\n",
    "def toKornia(img):\n",
    "    print(img.shape)\n",
    "    img = kornia.image_to_tensor(img) #Kornia in shape BCHW\n",
    "    print(img.shape)\n",
    "    # #Adding in dummy axis from: https://sparrow.dev/adding-a-dimension-to-a-tensor-in-pytorch/\n",
    "    # img = torch.unsqueeze(img, dim=0)\n",
    "    print(img.shape)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts images to grayscale\n",
    "# Implented during in class labs\n",
    "def img2grayscale(img):\n",
    "    img = img.astype(np.float32)/255\n",
    "    img = (img[:,:,0]+ img[:,:,1]+ img[:,:,2]) / 3\n",
    "\n",
    "    return img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in images\n",
    "leftImg = cv2.imread('parliament-left.jpg')\n",
    "plt.imshow(leftImg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
